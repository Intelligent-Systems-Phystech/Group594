\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\usepackage{calligra}
% \usepackage{gensymb}
\usepackage{siunitx}
% изменяет \mathcal
% \usepackage{calrsfs}

\newcommand{\x}{\mathbf{x}}
\newtheorem{theorem}{Def2}

%\NOREVIEWERNOTES
\title
    {Классификация символов на основе медиального представления и свёрточных сетей}
\author
    {Мурзин~Д.\,А., Данилов~А.\,Н., Местецкий~Л.\,М., Рейер~И.\,А., Жариков~И.\,Н., Стрижов~В.\,В.}
\thanks
    {Научный руководитель:  Стрижов~В.\,В. 
    Консультанты:  Местецкий~Л.\,М, Жариков~И.\,Н.}
\email
    {murzin.da@phystech.edu; andnlv@gmail.com; mestlm@mail.ru; reyer@forecsys.ru; zharikov.i.n@yandex.ru; strijov@phystech.edu}
\organization
    {Московский физико-технический институт}
\abstract 
    {В работе рассматривается задача распознавания символов на изображении. Предлагается новый способ построения свёрточной нейронной сети, использующей в качестве входа непрерывное представление цифрового изображения текстовых символов. В качестве тестовых данных используются символы латинского алфавита и цифры в растровом представлении.

\bigskip
\textbf{Ключевые слова}: \emph {классификация символов, непрерывное медиальное представление,
свёрточные нейронные сети}.}
\begin{document}
\maketitle
\section{Введение}
Работа посвящена задаче распознавания символов на изображении. Она используется для распознавания текста после сегментации на символы, что имеет множество применений, от оцифровки старых книг до распознавания рукописного текста.

Существующие методы распознавания текста можно разбить на две группы: «дискретные» и «непрерывные». Дискретные алгоритмы работают с изображением в первоначальном виде, то есть в виде матрицы пикселей. Данный формат описания изображения позволяет компьютерам эффективно их обрабатывать. Однако данный формат не является родным для людей, что приводит к сложности придумывания «дискретных» алгоритмов.

С другой стороны, непрерывные алгоритмы построены на использовании таких интуитивных для человека понятий как фигура и форма. Непрерывные алгоритмы устроены примерно следующим образом. Сначала строится непрерывное описание исходного изображения. Это может быть описание границы в виде кривых, либо медиальное представление, то есть набор кривых (скелет) и радиальная функция, которая каждой точке кривой сопоставляет максимальный радиус окружности, лежащей внутри фигуры, с центром в этой точке.

Дискретным алгоритмам распознавания символов посвящено большое количество работ. В частности в многих работах рассматривается классификации символов на базе данных рукописных цифр MNIST. Наилучшую точность показали алгоритмы использующие свёрточные нейронные сети \cite{previous_work_mnist21,previous_work_mnist23,previous_work_mnist23-2,previous_work_mnist24}. Так в работе \cite{previous_work_mnist23} предлагается алгоритм классификации, использующий ансамбль из 35 свёрточных сетей, дающий точность 99.77\%.

Непрерывным алгоритмам посвящено меньшее число работ. В книге \cite{mest2009} вводятся основные понятия связанные с непрерывным описанием изображения и предлагается алгоритм построения этого описания. В работах \cite{han2016, vizilter2018, morozov2017} рассматриваются подходы к построения классификатора на непрерывных описаниях изображения.

В работе предлагается развить подходы \cite{mest2009, han2016}. По дискретному описанию изображения строится непрерывное описание, с помощью алгоритма предложенного в \cite{mest2009}. Это непрерывное описание представляет собой граф специального вида. Данное описание преобразуется путём генерации новых признаков для каждой вершины графа. Полученный граф передаётся в классификатор на основе свёрточной нейронной сети, предложенный в \cite{han2016}.

\section{Постановка задачи}

В работе решается задача распознавания печатных символов на изображении. Требуется построить классификатор, принимающий описание изображения и возвращающий класс символа, изображённого на изображении. Описание изображения состоит из пары --- <<дискретного>> и <<непрерывного>> описаний. <<Дискретное>> описание представляет матрицу пикселей цветов. Непрерывное описание представляет собой граф специального вида. Введём строгие определения.

% В работе решается задача распознавания рукописных символов на изображении. Рассматриваются два варианта постановки задачи, <<дискретный>> и <<непрерывный>>. В обоих вариантах первоначальным входом классификатора является дискретное изображение. В <<дискретном>> варианте классификатор работает непосредственно с этим дискретным изображением, в то время как в <<непрерывном>> варианте классификатор работает с непрерывным медиальным представлением, являющимся результатом обработки исходного дискретного изображения. 
% Введём определения, необходимые для постановки задачи.

\paragraph{Определения для <<дискретного>> описания.}

%\begin{Def}
%$\mathcal{C}$ --- множество цветов, которые может принимать один пиксель изображения.
%\end{Def}
%В работе всегда предполагается $\mathcal{C}=\{0,1\}$, где один соответствует белому цвету, а ноль чёрному. 
% Другими возможными вариантами могут быть $\mathcal{C}=\{0,1,\ldots,255\}$ --- оттенки серого и $\mathcal{C}=\{0,1,\ldots,255\}^3$ --- цветовое пространство RGB.

\begin{Def}
Дискретное изображения высоты $h$ и ширины $w$ --- бинарная матрица из $h$ строк и $w$ столбцов. Каждый элемент матрицы описывает цвет одного пикселя изображения: ноль --- черный, один --- белый.

\end{Def}

\paragraph{Определения для <<непрерывного>> описания.}

\begin{Def}
Жорданова кривая --- образ окружности при непрерывном инъективном отображении окружности в плоскость.
\end{Def}

\begin{Def}
Фигура --- замкнутая область на плоскости $\mathbb{R}^2$, ограниченная конечным числом непересекающихся жордановых кривых.
\end{Def}

\begin{Def}
Пустой круг фигуры --- круг, полностью содержащийся внутри фигуры.
\end{Def}

\begin{Def}
Максимальный пустой круг фигуры --- пустой круг, который не содержится ни в каком другом пустом круге этой фигуры.
\end{Def}

\begin{Def}
Скелет фигуры --- множество всех центров максимальных пустых кругов фигуры.
\end{Def}

\begin{Def}
Радиальная функция для скелета фигуры --- функция, которая каждой точке скелета сопоставляет радиус максимального круга с центром в этой точке.
\end{Def}

\begin{Def}
Медиальное представление фигуры --- скелет фигуры с соответствующей медиальной функцией.
\end{Def}

% В работе предлагается использовать алгоритм скелетизации [добавить ссылку], выдающий медиальное представление в следующем формате: скелет задан в виде плоского графа (вершины --- точки плоскости, рёбра --- отрезки), радиальная функция задана на каждой вершине этого графа, а значение радиальной функции на рёбрах определяется как взвешенное среднее радиальной функции на концах ребра. Также, дополнительно, каждая вершина имеет степень от одного до трёх.

Перейдём к постановке задачи. Пусть задано множество символов $\mathcal{Y}$ мощности $k$ и выборка изображений, содержащих символы:

$$\mathfrak{D}=\{(I_i,y_i)\}_{i=1}^m$$

\begin{itemize}
    \item $I_i$ --- дискретное описание изображения
    % \item $G_i$ --- непрерывное описание изображения
    \item $y_i \in \mathcal{Y}$ --- класс символа
\end{itemize}

Требуется построить классификатор $f$, решающий задачу классификации символов, то есть, принимающий описание изображения в том же формате как в исходной выборке и возвращающий вектор вероятностей $\hat{p}=\{\hat{p}_1,\ldots,\hat{p}_k\}$, где $\hat{p}_i \in [0, 1]$, причём $\hat{p}_1+\ldots+\hat{p}_k=1$:

$$f: I \mapsto (\hat{p_1},\ldots,\hat{p_k}),$$

где $\hat{p}_i$ --- предсказание вероятности того что на изображение находится символ $s_i$.

Классификатор $f$ является композицией трёх алгоритмов:
\begin{itemize}
    \item $\mu: I \mapsto G$ --- алгоритм построения медиального представления. Используются библиотека
скелетонизации Никиты Ломова и скрипты для запуска Анны
Липкиной [добавить ссылку]. 
    \item $g: G \mapsto F$ --- алгоритм генерации признаков по медиальному представлению.
    \item $h: F \mapsto \hat{p}$ --- классификатор на основе свёрточных сетей для графов. Используется библиотека DeepChem [добавить ссылку].
\end{itemize}


\paragraph{Информация о выборке.}

В работе предлагается использовать изображения, полученные с помощью генератора символов латинского алфавита и цифр [добавить цитату]. Каждое изображение имеет размер $64\times64$, а цвета пикселей кодируются числами 0 и 1 (чёрный и белый соответственно). При этом расстояние от символа до границ изображения строго больше нуля.


\paragraph{Функция ошибки.}

В качестве функции ошибки для оценки качества классификатора используется кросс-энтропия (cross entropy):

$$H(p, \hat{p}) = -\sum_{i=1}^k p_i\log{\hat{p_i}}$$

где $p$ --- истинный вектор вероятностей (все нули кроме одного элемента), $\hat{p}$ --- предсказание вероятностей.
[Тут не понятно с обозначениями]

%-------------------------------------------------------------------- Теор. часть

\section{Теоретическая часть}

\paragraph{Алгоритм скелетонизации} $\mu$ выдаёт медиальное представление следующего вида: скелет задан в виде плоского графа (вершины --- точки плоскости, рёбра --- отрезки), радиальная функция задана на каждой вершине этого графа, а значение радиальной функции на рёбрах определяется как взвешенное среднее радиальной функции на концах ребра.

Формально, получаемое медиальное представление является парой:
$$G = \{X, E\}$$
где
\begin{itemize}
\item $X = \{\x_u\ |\ u \in \{1, \ldots, n\}\}$ --- описание вершин графа
    \begin{itemize}
    \item $n$ --- число вершин графа
    \item $\x_u$ --- описание вершины $u$ графа, $\x_u = (x_u, y_u, \rho_u)$
            \begin{itemize}
            \item $x_u, y_u$ --- координаты вершины
            \item $\rho_u$ --- значение радиальной функции в вершине
            \end{itemize}
    \end{itemize}
\item $E = \{(u,v)\}$ --- рёбра графа
\end{itemize}
Дополнительно, каждая вершина имеет степень от одного до трёх.

\paragraph{Алгоритм генерации признаков} $g$ преобразует заданное в виде графа медиальное представление, а именно к базовым признакам $(x_u, y_u, \rho_u)$ каждой вершины $u$ добавляется вектор признаков $f = (f_1, \ldots, f_k)$. Формально, получается пара

$$G = \{F, E\}$$
где
\begin{itemize}
\item $F = \{\mathbf{f}_u\ |\ u \in \{1, \ldots, n\}\}$ --- признаки вершин графа
    \begin{itemize}
    \item $n$ --- число вершин графа
    \item $\mathbf{f}_u$ --- признаки вершины $u$ графа, $\mathbf{f}_u = (f_1, \ldots, f_k)$. Первые три признака совпадают с базовыми --- $(x_u, y_u, \rho_u)$.
    \end{itemize}
\item $E = \{(u,v)\}$ --- рёбра графа
\end{itemize}

Опишем каждый признак, способ его генерации и мотивацию для него.

Степень вершины. Получается непосредственно по графу. Интерес представляет соотношение между количеством вершин степени три и один, а также количество вершин степени четыре. В зависимости от наличия вершин степени три и более символы разбиваются на два класса размера 32 и 31. Вершину степени четыре содержат 8 символов.

Число циклов графа, в котором содержится вершина. Получается предварительным выделением всех циклов графа с помощью поиска в глубину. Предикат наличия циклов в графе разбивает символы на два класса размера 18 и 44.

Средняя площадь циклов, в которых содержится данная вершина. Позволяет разделить символы с большим циклом (0, D, Q) и с маленьким (4, a, p).

Минимальный угол между рёбрами, исходящими из вершины. Полезен для вершин степени два, так как позволяет отделить символы похожие на прямые (i, l) от символов с изгибами (w, z)

Расстояние до ближайшей вершины степени один.

Сумма углов поворота между рёбрами на пути к ближайшей вершине степени один. Позволяет отделить немного изогнутые символы (j, f, 9) от символов с прямыми линиями (k, w, 4)

Длина максимальной прямой линии, в которой содержится текущая вершина. Прямая линия --- путь в графе, такой что угол между каждой парой соседних рёбер отличается не более чем на \ang{10} от \ang{180}. Позволяет отделить символы с длинными линиями (p, q, F, M).

Угол между максимальной прямой линией и горизонталью.

\paragraph{Алгоритм классификации} $h$ --- это свёрточная нейронная сеть для графов, которая использует три базовые операции: свёртки, активации и пулинга.

\begin{figure}[h]
\includegraphics[scale=0.4, inner] {images/cnn-graph.png} 
\end{figure}
[не вставляется картинка]

\paragraph{Операция свёртки} производится независимо для каждой вершины $u$ графа. Обозначим $d = \text{degree}(v)$ --- степень вершины $v$. Рассмотрим вершину $v$, смежную с ней. Обозначим $l = \text{distance}(u, v)$ --- евклидово расстояние между вершинами $u$ и $v$. Вершине $v$ соответствуют признаки $f_1, \ldots, f_{k_1}$. Операция свёртки состоит из двух этапов:

\begin{itemize}
\item для каждой смежной с $u$ вершины $v$ строится промежуточные вектора признаков, на основе степени вершины $u$ и расстояния $l$
\item промежуточные вектора всех смежных с $u$ вершин складываются, в результате получается новый вектор признаков вершины $u$
\end{itemize}

Для построения промежуточных векторов используются матрицы $W_{d,l} \in \mathbb{R}^{k_1 \times k_2}$ ($k_1$ --- число признаков до операции свёртки, $k_2$ --- после) и вектор $b_{d,l} \in \mathbb{R}^{k_2}$. Расстоянию $l$ сопоставляется матрица $W$ и вектор $b$ путём дискретизации вещественного значения расстояния $l$, а именно рассматриваются положительные вещественные числа $0 = b_1 < b_2 < \ldots $, разбивающие положительную числовую прямую на классы $\mathbb{R}_+ = [b_1, b_2)\ \bigcup\ [b_2, b_3)\ \bigcup\ \ldots$.

Тогда в результате операции свёртки получаются новые признаки для вершины $u$:
$$h_{\text{conv}}(u) = \sum_{(u, v) \in E} \big(W_{d,l} f_v + b_{d,l}\big)$$

\paragraph{Операция активации} также производится независимо для каждой вершины $u$ графа. Рассматриваются вектор признаков вершины $u$, вектора признаков всех смежных с $u$ вершин. К данным векторам применяется операция максимума и получается новый вектор признаков для вершины $u$:
$$h_{\text{relu}}(u) = \max(f_u, \max_{(u,v) \in E} f_v)$$

\paragraph{Операция пулинга} применяется к группе вершин $(u_1, \ldots, u_k)$ графа. Данные вершины заменяются одной, с вектором признаков, равным сумме векторов признаков исходных вершин:
$$h_{\text{pool}}(v_1, \ldots, v_k) = \sum_{i=1}^k(f_{v_i})$$

%------------------------------------------------------------------ Базовый эксперимент

\section{Базовый вычислительный эксперимент}

В качестве базового алгоритма используется свёрточная нейронная сеть для задачи в дискретной постановке. Предлагается использовать следующую структуру сети:

[Структура сети будет уточняться по ходу эксперимента]
$$\text{INPUT} \rightarrow [[\text{CONV} \rightarrow \text{RELU}]\times2 \rightarrow \text{POOL}]\times2 \rightarrow \text{FC}$$

\begin{itemize}
    \item INPUT --- входной слой, имеет размеры $28\times28\times1$
    \item CONV --- слой свёртки. Фильтры имеют размер $3\times3$. Также используется увеличение пространственных размеров на 2 в каждой размерности предыдущего слоя путём дополнения одинарной линией из нулей с каждой стороны.
    \item RELU --- слой активации. Используется функция $f(x)=\ln(1 + \exp(x))$
    \item POOL --- слой пулинга. Каждая группа пикселей $2\times2$ уплотняется в один пиксель, путём взятия максимума.
    \item FC --- полносвязный слой. 
\end{itemize}

\section{Вычислительный эксперимент}

...



\nocite{*}
\bibliography{article}
\bibliographystyle{unsrt}

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}
