{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "1. Изменить константы в модели\n",
    "2. Сделать модель для произвольного числа атомов\n",
    "3. Добавить больше признаков, в том числе задействующие 3 и более вершины\n",
    "4. Разобраться с тем, почему не получается считать все файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приготовим данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def line_processing(line):\n",
    "    'для извлечения чисел из матриц'\n",
    "    line = re.split('[^0-9,.,]+', line)\n",
    "    i = 0\n",
    "    while(i < len(line)):\n",
    "        if(line[i] == ''):\n",
    "            line.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "    return line\n",
    "\n",
    "def read_matrix_row(file):\n",
    "    line = file.readline()\n",
    "    while(line[-2] != ']'):\n",
    "        tmp = file.readline()\n",
    "        line += tmp\n",
    "    return line_processing(line)\n",
    "\n",
    "def read_matrix(file):\n",
    "    line = read_matrix_row(file)\n",
    "    #количество атомов\n",
    "    n  = len(line)\n",
    "    \n",
    "    result = []\n",
    "    for i in range(n):\n",
    "        row = []\n",
    "        if(n > len(line)):\n",
    "            print(\"hi\", i)\n",
    "            print(line)\n",
    "        for j in range(n):\n",
    "            row.append(float(line[j]))\n",
    "        if(i < n - 1):\n",
    "            line = read_matrix_row(file)\n",
    "        result.append(row)\n",
    "    return np.array(result)\n",
    "\n",
    "def read_atoms_features_and_labels(file, n): \n",
    "    features = []\n",
    "    labels = []\n",
    "    for _ in range(n):\n",
    "        line = file.readline()\n",
    "        line = line.split()\n",
    "        #add as features element electronegativity, is in ring, triple product\n",
    "        #if triple product is None, we consider it 0\n",
    "        features.append([float(line[3]), float(line[7]), 0.0 if line[8] == 'None' else float(line[8])])\n",
    "        #type2 is a label\n",
    "        labels.append(float(line[4]))\n",
    "    return np.array(features), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_molecule(path):\n",
    "    file = open(path, 'r')\n",
    "    file.readline()\n",
    "    adjacency_matrix = read_matrix(file)\n",
    "    file.readline()\n",
    "    distance_matrix = torch.from_numpy(read_matrix(file)).float()\n",
    "    \n",
    "    for _ in range(3):\n",
    "        file.readline()\n",
    "    atoms_features, atoms_labels = read_atoms_features_and_labels(file, distance_matrix.shape[0])\n",
    "    atoms_features = Variable(torch.from_numpy(atoms_features).float())\n",
    "    atoms_labels = Variable(torch.from_numpy(atoms_labels).float())\n",
    "    \n",
    "    file.readline()\n",
    "    bond_length = torch.from_numpy(read_matrix(file)).float()\n",
    "    pairs_features = Variable(torch.cat([distance_matrix[..., np.newaxis], bond_length[..., np.newaxis]], dim=2))\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    # Проверим, что всё хорошо считали\n",
    "    assert(adjacency_matrix.shape[0] == adjacency_matrix.shape[1])\n",
    "    assert(distance_matrix.shape[0] == distance_matrix.shape[1])\n",
    "    assert(bond_length.shape[0] == bond_length.shape[1])\n",
    "    assert(distance_matrix.shape[0] == adjacency_matrix.shape[1])\n",
    "    assert(bond_length.shape[0] == adjacency_matrix.shape[1])\n",
    "    \n",
    "    #Теперь приготовим входные данные для сети\n",
    "    inputs_a = Variable(torch.Tensor(atoms_features.shape[0], 1, atoms_features.shape[0], atoms_features.shape[1]))\n",
    "    inputs_p = Variable(torch.Tensor(atoms_features.shape[0], 1, pairs_features.shape[0], pairs_features.shape[1], pairs_features.shape[2]))\n",
    "    for i in range(atoms_features.shape[0]):\n",
    "        inputs_a[i] = atoms_features\n",
    "        inputs_p[i] = pairs_features\n",
    "    labels=atoms_labels.long()\n",
    "    labels.add_(-1)\n",
    "    \n",
    "    return [inputs_a, inputs_p, adjacency_matrix, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = []\n",
    "test = []\n",
    "# путь к директории, где лежат модели\n",
    "data_path = \"mol-descs/descs/\"\n",
    "pathes = os.listdir(path=data_path)\n",
    "pathes = [path for path in pathes if path[-4:] == '.dat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующие несколько ячеек не объединены в одну только потому, что мой комп выключается"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in pathes[:800]:\n",
    "    train.append(read_molecule(data_path + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in pathes[800:1600]:\n",
    "    train.append(read_molecule(data_path + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in pathes[1600:2400]:\n",
    "    test.append(read_molecule(data_path + path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [train_[0].shape[0] for train_ in train]\n",
    "bc = np.bincount(a)\n",
    "np.argmax(bc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поэтому пока настроим сеть для молекул из 27 атомов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, wave_modules_count=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.wave_modules_count = wave_modules_count\n",
    "        self.conv1 = nn.Conv1d(1, 1, 3)\n",
    "        self.conv2 = nn.Conv1d(1, 1, 2)\n",
    "        self.fc1 = nn.Linear(27 * 2, 4)\n",
    "    \n",
    "    def wave_module(self, x, y, adjacency_matrix):\n",
    "        # (A->A)\n",
    "        \"TODO заменить константу в размере вектора\"\n",
    "        x1 = Variable(torch.Tensor(x.shape[0], x.shape[1], x.shape[2], 1))\n",
    "        for i in range(x1.shape[2]):\n",
    "            x1[:, :, i] = F.relu(self.conv1(x[:, :, i]))\n",
    "        \n",
    "        # (P->P)\n",
    "        \"TODO заменить константу в размере вектора\"\n",
    "        y1 = Variable(torch.Tensor(y.shape[0], y.shape[1], y.shape[2], y.shape[3], 1))\n",
    "        for i in range(y1.shape[2]):\n",
    "            for j in range(y1.shape[3]):\n",
    "                y1[:, :, i, j] = F.relu(self.conv2(y[:, :, i, j]))\n",
    "                \n",
    "        # (P->A)\n",
    "        # сначала получим для каждой вершины смежные вершины\n",
    "        edges = []\n",
    "        for i in range(adjacency_matrix.shape[0]):\n",
    "            tmp = []\n",
    "            for j in range(len(adjacency_matrix[i])):\n",
    "                if(adjacency_matrix[i][j] == 1):\n",
    "                    tmp.append(j)\n",
    "            edges.append(tmp)\n",
    "        # теперь непосредственно получаем новый слой, используя y1\n",
    "        \"TODO заменить константу в размере вектора\"\n",
    "        x2 = Variable(torch.Tensor(x.shape[0], x.shape[1], x.shape[2], 1))\n",
    "        for i in range(x2.shape[0]):\n",
    "            x2[:, :, i] = y1[:, :, i, edges[i][0]]\n",
    "            for j in range(1, len(edges[i])):\n",
    "                x2[:, :, i] = x2[:, :, i] + y1[:, :, i, edges[i][j]]\n",
    "            #x2[:, :, i] = torch.sum([y1[:, :, i, b] for b in edges[i]], dim=2)\n",
    "        \n",
    "        # (A -> P)\n",
    "        \"TODO заменить константу в размере вектора\"\n",
    "        y2 = Variable(torch.Tensor(y.shape[0], y.shape[1], y.shape[2], y.shape[3], 4))\n",
    "        for i in range(y2.shape[2]):\n",
    "            for j in range(y2.shape[3]):\n",
    "                y2[:, :, i, j] = torch.add(F.relu(self.conv1(torch.cat([x[:, :, i], x[:, :, j]], dim=2))),\n",
    "                           F.relu(self.conv1(torch.cat([x[:, :, j], x[:, :, i]], dim=2))) )\n",
    "        \n",
    "        # теперь плучаем новые атомный и парный слои\n",
    "        x_ret = torch.cat([x1, x2], dim = 3)\n",
    "        y_ret = torch.cat([y1, y2], dim = 4)\n",
    "        \n",
    "        return [x_ret, y_ret]\n",
    "        \n",
    "    def forward(self, x, y, adjacency_matrix):\n",
    "        for _ in range(self.wave_modules_count):\n",
    "            x, y = self.wave_module(x, y, adjacency_matrix)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры оптимизатора взяты из модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adagrad(net.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 0.922\n",
      "[1,    20] loss: 0.865\n",
      "[1,    30] loss: 0.671\n",
      "[1,    40] loss: 0.927\n",
      "[1,    50] loss: 0.833\n",
      "[1,    60] loss: 0.706\n",
      "[2,    10] loss: 0.709\n",
      "[2,    20] loss: 0.768\n",
      "[2,    30] loss: 0.642\n",
      "[2,    40] loss: 0.893\n",
      "[2,    50] loss: 0.813\n",
      "[2,    60] loss: 0.682\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "    \n",
    "    appopr_data_pos = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train, 0):\n",
    "        # get the inputs\n",
    "        inputs_a, inputs_p, adjacency_matrix, labels = data\n",
    "        if(inputs_a.shape[0] == 27):\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net.forward(inputs_a, inputs_p, adjacency_matrix)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.data[0]\n",
    "            if appopr_data_pos % 10 == 9:    # print every 10 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, appopr_data_pos + 1, running_loss / 10))\n",
    "                running_loss = 0.0\n",
    "            appopr_data_pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 60 test molecules: 55 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in test:\n",
    "    inputs_a, inputs_p, adjacency_matrix, labels = data\n",
    "    if(inputs_a.shape[0] == 27):\n",
    "        outputs = net(inputs_a, inputs_p, adjacency_matrix)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.data).sum()\n",
    "\n",
    "print('Accuracy of the network on the 60 test molecules: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
